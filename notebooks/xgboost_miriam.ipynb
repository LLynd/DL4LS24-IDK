{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and setting global seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning_lite in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (1.8.6)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (1.12.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from fsspec[http]>2021.06.0->lightning_lite) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (4.11.0)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (0.11.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from fsspec[http]>2021.06.0->lightning_lite) (3.9.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning-utilities!=0.4.0,>=0.3.0->lightning_lite) (68.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install lightning_lite\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lightning_lite import seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping  # ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "seed_everything(10, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score=0.5\n",
    "colsample_bylevel=1\n",
    "colsample_bytree=1\n",
    "gamma=0\n",
    "learning_rate=0.1\n",
    "max_depth=3\n",
    "min_child_weight=1\n",
    "seed=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from path, converting objs to a dataframe for analysis and prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/miria/OneDrive/Documents/AMatematyka/aaaaDL4LS/DL4LS24-IDK-main/data/train/cell_data.h5ad\"\n",
    "### input Your path\n",
    "\n",
    "anndata = ad.read_h5ad(path)\n",
    "anndata.layers\n",
    "anndata.X = anndata.layers['exprs'] # FIX!\n",
    "\n",
    "df=anndata.obs\n",
    "counts=anndata.layers['counts']\n",
    "exprs=anndata.layers['exprs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236791, 39)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending information from counts and exprs to dataframe for prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols_exprs=['exprs'+str(i) for i in range(40)]\n",
    "df_exprs = pd.DataFrame(data=exprs, columns=list_cols_exprs,index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236791, 79)\n"
     ]
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "merged_df = pd.concat([df1, df_exprs], axis=1)\n",
    "print(merged_df.shape)\n",
    "\n",
    "\n",
    "df=merged_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTTT ---wyciete dane z obs, komorka do usuniecia raczej, pokazuje ze mamy dobre wartosci na samych counts i exprs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9719799826854452\n",
      "Macro F1 score: 0.9458052709988252\n",
      "AUC score (OvR): 0.9994492257959756\n",
      "Average Precision score: 0.9839467390880151\n"
     ]
    }
   ],
   "source": [
    "'''df_test=pd.concat([df_exprs, df_counts], axis=1)\n",
    "y=df['cell_labels']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_encoded1 = encoder.fit_transform(y)\n",
    "\n",
    "seed = 10\n",
    "test_size=0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_test, y_encoded1, test_size=test_size, random_state=seed)\n",
    "\n",
    "xgb_clf1 = xgb.XGBClassifier()\n",
    "xgb_clf1 = xgb_clf1.fit(X_train, Y_train)\n",
    "\n",
    "predictions=xgb_clf1.predict(X_test)\n",
    "predictions_probabilities=xgb_clf1.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "macro_f1 = f1_score(Y_test, predictions, average='macro')\n",
    "print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "auc = roc_auc_score(Y_test, predictions_probabilities, multi_class='ovr')\n",
    "print(\"AUC score (OvR):\", auc)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, predictions_probabilities)\n",
    "print(\"Average Precision score:\", average_precision)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing; \n",
    "1. Remove unneccesary columns \n",
    "2. One-hot encode categorical ones \n",
    "3. End up with only float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:  Index(['image', 'sample_id', 'ObjectNumber', 'Pos_X', 'Pos_Y', 'area',\n",
      "       'major_axis_length', 'minor_axis_length', 'eccentricity', 'width_px',\n",
      "       'height_px', 'acquisition_id', 'SlideId', 'Study', 'Box.Description',\n",
      "       'Position', 'SampleId', 'Indication', 'BatchId', 'SubBatchId', 'ROI',\n",
      "       'ROIonSlide', 'includeImage', 'flag_no_cells', 'flag_no_ROI',\n",
      "       'flag_total_area', 'flag_percent_covered', 'small_cell', 'celltypes',\n",
      "       'flag_tumor', 'PD1_pos', 'Ki67_pos', 'cleavedPARP_pos', 'GrzB_pos',\n",
      "       'tumor_patches', 'distToCells', 'CD20_patches', 'Batch', 'cell_labels',\n",
      "       'exprs0', 'exprs1', 'exprs2', 'exprs3', 'exprs4', 'exprs5', 'exprs6',\n",
      "       'exprs7', 'exprs8', 'exprs9', 'exprs10', 'exprs11', 'exprs12',\n",
      "       'exprs13', 'exprs14', 'exprs15', 'exprs16', 'exprs17', 'exprs18',\n",
      "       'exprs19', 'exprs20', 'exprs21', 'exprs22', 'exprs23', 'exprs24',\n",
      "       'exprs25', 'exprs26', 'exprs27', 'exprs28', 'exprs29', 'exprs30',\n",
      "       'exprs31', 'exprs32', 'exprs33', 'exprs34', 'exprs35', 'exprs36',\n",
      "       'exprs37', 'exprs38', 'exprs39'],\n",
      "      dtype='object')\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miria\\AppData\\Local\\Temp\\ipykernel_25284\\1152296002.py:16: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df['CD20_patches'] = df['CD20_patches'].replace('', '0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectNumber          float64\n",
       "Pos_X                 float64\n",
       "Pos_Y                 float64\n",
       "area                  float64\n",
       "major_axis_length     float64\n",
       "                       ...   \n",
       "Study_180311_GI       float64\n",
       "Study_180327_HN       float64\n",
       "Study_180345_BREAS    float64\n",
       "Study_190346_GU       float64\n",
       "Study_190370_SPECT    float64\n",
       "Length: 80, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All columns: \",df.columns)\n",
    "int_columns = df.select_dtypes(include='int').columns.tolist()\n",
    "df[int_columns] = df[int_columns].astype(float)\n",
    "\n",
    "non_float_columns = df.select_dtypes(exclude='float').columns.tolist()\n",
    "'''for column in non_float_columns:\n",
    "    print(f\"{column}: {df[column].dtype}\")'''\n",
    "category_columns = df.select_dtypes(include='category').columns.tolist()\n",
    "print(df['sample_id'].equals(df['SampleId']))\n",
    "ids=df['sample_id']\n",
    "Y=df['cell_labels']\n",
    "\n",
    "columns_to_remove=['SampleId','image','sample_id','SlideId','BatchId','SubBatchId','Batch','Box.Description','cell_labels','celltypes']\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "df['CD20_patches'] = df['CD20_patches'].replace('', '0')\n",
    "df['CD20_patches'] = df['CD20_patches'].astype(float)\n",
    "\n",
    "category_columns = df.select_dtypes(include='category').columns.tolist()\n",
    "category_columns\n",
    "\n",
    "one_hot_encoded1 = pd.get_dummies(df['Indication'], prefix='Indication')\n",
    "one_hot_encoded1\n",
    "one_hot_encoded1= one_hot_encoded1.astype(float)\n",
    "df = df.join(one_hot_encoded1)\n",
    "\n",
    "one_hot_encoded2 = pd.get_dummies(df['Study'], prefix='Study')\n",
    "one_hot_encoded2= one_hot_encoded2.astype(float)\n",
    "one_hot_encoded2\n",
    "df = df.join(one_hot_encoded2)\n",
    "df = df.drop(columns=['Indication','Study'])\n",
    "category_columns = df.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe df is now filled with float values, Y is our label derived from cell_labels column, we encode it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(Y)\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is our data which is going to be fed to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.copy()\n",
    "seed = 10\n",
    "test_size=0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y_encoded, test_size=test_size, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train XGboost model on a train set (should take 2mins on 0.8 of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(base_score=base_score, colsample_bylevel=colsample_bylevel, colsample_bytree=colsample_bytree,max_depth=max_depth,\n",
    "                             min_child_weight=min_child_weight,gamma=gamma, learning_rate=learning_rate, seed=10)\n",
    "\n",
    "xgb_clf = xgb_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make predictions for test set and calculate metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=xgb_clf.predict(X_test)\n",
    "predictions_probabilities=xgb_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9655186976076353\n",
      "Macro F1 score: 0.9271945217141659\n",
      "AUC score (OvR): 0.9989213301507792\n",
      "Average Precision score: 0.9715489976059903\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "macro_f1 = f1_score(Y_test, predictions, average='macro')\n",
    "print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "auc = roc_auc_score(Y_test, predictions_probabilities, multi_class='ovr')\n",
    "print(\"AUC score (OvR):\", auc)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, predictions_probabilities)\n",
    "print(\"Average Precision score:\", average_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model trained on the whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(base_score=base_score, colsample_bylevel=colsample_bylevel, colsample_bytree=colsample_bytree,max_depth=max_depth,\n",
    "                             min_child_weight=min_child_weight,gamma=gamma, learning_rate=learning_rate, seed=10)\n",
    "\n",
    "xgb_clf = xgb_clf.fit(X, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input='...'\n",
    "new_output='...'\n",
    "\n",
    "predictions=xgb_clf.predict(new_input)\n",
    "predictions_probabilities=xgb_clf.predict_proba(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(new_output, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "macro_f1 = f1_score(new_output, predictions, average='macro')\n",
    "print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "auc = roc_auc_score(new_output, predictions_probabilities, multi_class='ovr')\n",
    "print(\"AUC score (OvR):\", auc)\n",
    "\n",
    "average_precision = average_precision_score(new_output, predictions_probabilities)\n",
    "print(\"Average Precision score:\", average_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4ls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

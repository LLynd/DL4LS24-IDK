{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and setting global seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning_lite in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (1.8.6)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (1.12.1)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from fsspec[http]>2021.06.0->lightning_lite) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (4.11.0)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning_lite) (0.11.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from fsspec[http]>2021.06.0->lightning_lite) (3.9.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from lightning-utilities!=0.4.0,>=0.3.0->lightning_lite) (68.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (4.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning_lite) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install lightning_lite\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lightning_lite import seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping  # ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "seed_everything(10, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_num_epochs=50\n",
    "final_lr=0.003\n",
    "final_hidden_size=100\n",
    "final_batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data from path, converting objs to a dataframe for analysis and prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/miria/OneDrive/Documents/AMatematyka/aaaaDL4LS/DL4LS24-IDK-main/data/train/cell_data.h5ad\"\n",
    "### input Your path\n",
    "\n",
    "anndata = ad.read_h5ad(path)\n",
    "anndata.layers\n",
    "anndata.X = anndata.layers['exprs'] # FIX!\n",
    "\n",
    "df=anndata.obs\n",
    "counts=anndata.layers['counts']\n",
    "exprs=anndata.layers['exprs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending information from counts and exprs to dataframe for prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_cols_exprs=['exprs'+str(i) for i in range(40)]\n",
    "\n",
    "df_exprs = pd.DataFrame(data=exprs, columns=list_cols_exprs,index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(236791, 79)\n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([df, df_exprs], axis=1)\n",
    "\n",
    "print(result.shape)\n",
    "df=result.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing; \n",
    "1. Remove unneccesary columns \n",
    "2. One-hot encode categorical ones \n",
    "3. End up with only float values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns:  Index(['image', 'sample_id', 'ObjectNumber', 'Pos_X', 'Pos_Y', 'area',\n",
      "       'major_axis_length', 'minor_axis_length', 'eccentricity', 'width_px',\n",
      "       'height_px', 'acquisition_id', 'SlideId', 'Study', 'Box.Description',\n",
      "       'Position', 'SampleId', 'Indication', 'BatchId', 'SubBatchId', 'ROI',\n",
      "       'ROIonSlide', 'includeImage', 'flag_no_cells', 'flag_no_ROI',\n",
      "       'flag_total_area', 'flag_percent_covered', 'small_cell', 'celltypes',\n",
      "       'flag_tumor', 'PD1_pos', 'Ki67_pos', 'cleavedPARP_pos', 'GrzB_pos',\n",
      "       'tumor_patches', 'distToCells', 'CD20_patches', 'Batch', 'cell_labels',\n",
      "       'exprs0', 'exprs1', 'exprs2', 'exprs3', 'exprs4', 'exprs5', 'exprs6',\n",
      "       'exprs7', 'exprs8', 'exprs9', 'exprs10', 'exprs11', 'exprs12',\n",
      "       'exprs13', 'exprs14', 'exprs15', 'exprs16', 'exprs17', 'exprs18',\n",
      "       'exprs19', 'exprs20', 'exprs21', 'exprs22', 'exprs23', 'exprs24',\n",
      "       'exprs25', 'exprs26', 'exprs27', 'exprs28', 'exprs29', 'exprs30',\n",
      "       'exprs31', 'exprs32', 'exprs33', 'exprs34', 'exprs35', 'exprs36',\n",
      "       'exprs37', 'exprs38', 'exprs39'],\n",
      "      dtype='object')\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miria\\AppData\\Local\\Temp\\ipykernel_18672\\703076635.py:16: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  df['CD20_patches'] = df['CD20_patches'].replace('', '0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(236791, 80)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"All columns: \",df.columns)\n",
    "int_columns = df.select_dtypes(include='int').columns.tolist()\n",
    "df[int_columns] = df[int_columns].astype(float)\n",
    "\n",
    "non_float_columns = df.select_dtypes(exclude='float').columns.tolist()\n",
    "'''for column in non_float_columns:\n",
    "    print(f\"{column}: {df[column].dtype}\")'''\n",
    "category_columns = df.select_dtypes(include='category').columns.tolist()\n",
    "print(df['sample_id'].equals(df['SampleId']))\n",
    "ids=df['sample_id']\n",
    "Y=df['cell_labels']\n",
    "\n",
    "columns_to_remove=['SampleId','image','sample_id','SlideId','BatchId','SubBatchId','Batch','Box.Description','cell_labels','celltypes']\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)\n",
    "df['CD20_patches'] = df['CD20_patches'].replace('', '0')\n",
    "df['CD20_patches'] = df['CD20_patches'].astype(float)\n",
    "\n",
    "category_columns = df.select_dtypes(include='category').columns.tolist()\n",
    "category_columns\n",
    "\n",
    "one_hot_encoded1 = pd.get_dummies(df['Indication'], prefix='Indication')\n",
    "one_hot_encoded1\n",
    "one_hot_encoded1= one_hot_encoded1.astype(float)\n",
    "df = df.join(one_hot_encoded1)\n",
    "\n",
    "one_hot_encoded2 = pd.get_dummies(df['Study'], prefix='Study')\n",
    "one_hot_encoded2= one_hot_encoded2.astype(float)\n",
    "one_hot_encoded2\n",
    "df = df.join(one_hot_encoded2)\n",
    "df = df.drop(columns=['Indication','Study'])\n",
    "category_columns = df.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe df is now filled with float values, Y is our label derived from cell_labels column, we encode it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(Y)\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is our data which is going to be fed to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189432, 80) (47359, 80)\n"
     ]
    }
   ],
   "source": [
    "X=df.copy()\n",
    "\n",
    "'''\n",
    "### Normalization column wise\n",
    "X_np=X.to_numpy()\n",
    "nan_indices = np.isnan(X_np)\n",
    "num_nans = np.sum(nan_indices)\n",
    "\n",
    "# Print the number of NaN values\n",
    "print(\"Number of NaN values:\", num_nans)\n",
    "column_means = np.nanmean(X_np, axis=0)\n",
    "\n",
    "# Replace NaN values with column means\n",
    "X_np[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "nan_indices = np.isnan(X_np)\n",
    "num_nans = np.sum(nan_indices)\n",
    "print(\"Number of NaN values:\", num_nans)\n",
    "\n",
    "mean = np.mean(X_np, axis=0)\n",
    "std_dev = np.std(X_np, axis=0)\n",
    "\n",
    "# Apply z-score normalization\n",
    "normalized_data = (X_np - mean) / std_dev'''\n",
    "\n",
    "seed = 10\n",
    "test_size=0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y_encoded, test_size=test_size, random_state=seed)\n",
    "\n",
    "X_train=X_train.to_numpy()\n",
    "X_test=X_test.to_numpy()\n",
    "\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must deal with NaN values in the X set, we replace them with means from the columns, to avoid data loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values: 9435\n",
      "Number of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "nan_indices = np.isnan(X_train)\n",
    "num_nans = np.sum(nan_indices)\n",
    "\n",
    "print(\"Number of NaN values:\", num_nans)\n",
    "column_means = np.nanmean(X_train, axis=0)\n",
    "\n",
    "# We replace NaN values with column means\n",
    "X_train[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "nan_indices = np.isnan(X_train)\n",
    "num_nans = np.sum(nan_indices)\n",
    "print(\"Number of NaN values:\", num_nans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values: 2394\n",
      "Number of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "nan_indices = np.isnan(X_test)\n",
    "num_nans = np.sum(nan_indices)\n",
    "\n",
    "print(\"Number of NaN values:\", num_nans)\n",
    "column_means = np.nanmean(X_test, axis=0)\n",
    "\n",
    "# We replace NaN values with column means\n",
    "X_test[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "nan_indices = np.isnan(X_test)\n",
    "num_nans = np.sum(nan_indices)\n",
    "print(\"Number of NaN values:\", num_nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the linear classifier architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "X_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y_train, dtype=torch.long)  \n",
    "\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = LinearClassifier(input_size=X_tensor.shape[1], hidden_size=100, num_classes=14)\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "\n",
    "def train(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Calculate loss and acc\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8222, Accuracy: 0.7555\n",
      "Epoch 2/10, Loss: 0.5044, Accuracy: 0.8437\n",
      "Epoch 3/10, Loss: 0.4548, Accuracy: 0.8599\n",
      "Epoch 4/10, Loss: 0.4165, Accuracy: 0.8730\n",
      "Epoch 5/10, Loss: 0.3954, Accuracy: 0.8802\n",
      "Epoch 6/10, Loss: 0.3770, Accuracy: 0.8858\n",
      "Epoch 7/10, Loss: 0.3651, Accuracy: 0.8900\n",
      "Epoch 8/10, Loss: 0.3560, Accuracy: 0.8937\n",
      "Epoch 9/10, Loss: 0.3464, Accuracy: 0.8957\n",
      "Epoch 10/10, Loss: 0.3367, Accuracy: 0.8992\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train(model, dataloader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make predictions for test set and calculate metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47359, 14])\n"
     ]
    }
   ],
   "source": [
    "X_tensor_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_tensor_test = torch.tensor(Y_test, dtype=torch.long)  \n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs=model(X_tensor_test)\n",
    "    print(outputs.shape)\n",
    "    predictions_probabilities=torch.softmax(outputs,axis=1)\n",
    "    #predictions_probabilities /= predictions_probabilities.sum(axis=1, keepdims=True)\n",
    "    predictions_probabilities=predictions_probabilities.detach().numpy() \n",
    "    predictions=np.argmax(predictions_probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the desired scores and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9163411389598598\n",
      "Macro F1 score: 0.6942432854737298\n",
      "AUC score (OvR): 0.9836732313897321\n",
      "Average Precision score: 0.7630432734105855\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "macro_f1 = f1_score(Y_test, predictions, average='macro')\n",
    "print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "auc = roc_auc_score(Y_test, predictions_probabilities, multi_class='ovr')\n",
    "print(\"AUC score (OvR):\", auc)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, predictions_probabilities)\n",
    "print(\"Average Precision score:\", average_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Monte Carlo dropout for uncertainty analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def uncertainty_analysis(model, dataloader, num_samples=100):\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "            mc_predictions = torch.stack([model(inputs).softmax(dim=1) for _ in range(num_samples)], dim=0)\n",
    "            mean_prediction = mc_predictions.mean(dim=0)\n",
    "            predictive_entropy = -(mean_prediction * torch.log(mean_prediction)).sum(dim=1)\n",
    "            uncertainties.append(predictive_entropy.numpy())\n",
    "    return np.concatenate(uncertainties)\n",
    "\n",
    "\n",
    "def visualize_uncertainties(uncertainties):\n",
    "    plt.hist(uncertainties, bins=20)\n",
    "    plt.xlabel('Uncertainty')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Uncertainties')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add dropout possibility to a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7951, Accuracy: 0.7694\n",
      "Epoch 2/10, Loss: 0.4832, Accuracy: 0.8511\n",
      "Epoch 3/10, Loss: 0.4369, Accuracy: 0.8649\n",
      "Epoch 4/10, Loss: 0.4270, Accuracy: 0.8706\n",
      "Epoch 5/10, Loss: 0.4034, Accuracy: 0.8773\n",
      "Epoch 6/10, Loss: 0.3928, Accuracy: 0.8817\n",
      "Epoch 7/10, Loss: 0.3824, Accuracy: 0.8840\n",
      "Epoch 8/10, Loss: 0.3722, Accuracy: 0.8884\n",
      "Epoch 9/10, Loss: 0.3625, Accuracy: 0.8900\n",
      "Epoch 10/10, Loss: 0.3593, Accuracy: 0.8922\n",
      "Uncertainties: [1.77600038e+00 1.82851385e-02 1.59306219e-03 ... 1.21612206e-01\n",
      " 6.78264081e-01 2.48103788e-05]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class LinearClassifierWithDropout(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout_prob=0.01):\n",
    "        super(LinearClassifierWithDropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_prob)  # Dropout with probability dropout_prob\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_prob)  # Dropout with probability dropout_prob\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)  # Apply dropout during forward pass\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)  # Apply dropout during forward pass\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model_dropout = LinearClassifierWithDropout(input_size=X_tensor.shape[1], hidden_size=100, num_classes=14, dropout_prob=0.01)\n",
    "criterion_drop = nn.CrossEntropyLoss()  # Cross-entropy loss for classification  task\n",
    "optimizer_drop = optim.Adam(model_dropout.parameters(), lr=0.003)\n",
    "dataloader_drop = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# We train the model with dropout_prob=0\n",
    "train(model_dropout, dataloader_drop, criterion_drop, optimizer_drop, num_epochs=10)\n",
    "\n",
    "# Then we set dropout_prob=0.3 for uncertainty analysis\n",
    "model_dropout.dropout1.p = 0.3\n",
    "model_dropout.dropout2.p = 0.3\n",
    "\n",
    "\n",
    "uncertainties = uncertainty_analysis(model_dropout, dataloader)\n",
    "print(\"Uncertainties:\", uncertainties)\n",
    "\n",
    "uncertainties=np.nan_to_num(uncertainties)\n",
    "\n",
    "visualize_uncertainties(uncertainties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model trained on whole set: (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values: 0\n",
      "Number of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_all=X.to_numpy()\n",
    "nan_indices = np.isnan(X_all)\n",
    "num_nans = np.sum(nan_indices)\n",
    "\n",
    "print(\"Number of NaN values:\", num_nans)\n",
    "column_means = np.nanmean(X_all, axis=0)\n",
    "\n",
    "# We replace NaN values with column means\n",
    "X_all[nan_indices] = np.take(column_means, np.where(nan_indices)[1])\n",
    "nan_indices = np.isnan(X_all)\n",
    "num_nans = np.sum(nan_indices)\n",
    "print(\"Number of NaN values:\", num_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.8322, Accuracy: 0.7480\n",
      "Epoch 2/50, Loss: 0.4712, Accuracy: 0.8524\n",
      "Epoch 3/50, Loss: 0.4059, Accuracy: 0.8749\n",
      "Epoch 4/50, Loss: 0.3822, Accuracy: 0.8836\n",
      "Epoch 5/50, Loss: 0.3605, Accuracy: 0.8913\n",
      "Epoch 6/50, Loss: 0.3861, Accuracy: 0.8921\n",
      "Epoch 7/50, Loss: 0.3457, Accuracy: 0.8950\n",
      "Epoch 8/50, Loss: 0.3316, Accuracy: 0.8997\n",
      "Epoch 9/50, Loss: 0.3222, Accuracy: 0.9028\n",
      "Epoch 10/50, Loss: 0.3198, Accuracy: 0.9036\n",
      "Epoch 11/50, Loss: 0.3113, Accuracy: 0.9063\n",
      "Epoch 12/50, Loss: 0.3115, Accuracy: 0.9066\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()  \u001b[38;5;66;03m# Cross-entropy loss for classification\u001b[39;00m\n\u001b[0;32m     12\u001b[0m optimizer_final \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_final\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mfinal_lr)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_num_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[31], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     39\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[31], line 10\u001b[0m, in \u001b[0;36mLinearClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#x = F.softmax(x, dim=1)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\miria\\anaconda3\\envs\\dl4ls\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Y_all=y_encoded\n",
    "\n",
    "X_tensor_all = torch.tensor(X_all, dtype=torch.float32)\n",
    "Y_tensor_all = torch.tensor(Y_all, dtype=torch.long)  \n",
    "\n",
    "# Create DataLoader\n",
    "dataset = TensorDataset(X_tensor_all, Y_tensor_all)\n",
    "dataloader_final = DataLoader(dataset, batch_size=final_batch_size, shuffle=True)\n",
    "\n",
    "model_final = LinearClassifier(input_size=X_tensor.shape[1], hidden_size=final_hidden_size, num_classes=14)\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer_final = optim.Adam(model_final.parameters(), lr=final_lr)\n",
    "\n",
    "train(model_final, dataloader_final, criterion, optimizer_final, num_epochs=final_num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model on the new input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input='...'\n",
    "new_ouput='...'\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs=model_final(new_input)\n",
    "    print(outputs.shape)\n",
    "    predictions_probabilities=torch.softmax(outputs,axis=1)\n",
    "    #predictions_probabilities /= predictions_probabilities.sum(axis=1, keepdims=True)\n",
    "    predictions_probabilities=predictions_probabilities.detach().numpy() \n",
    "    predictions=np.argmax(predictions_probabilities, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(new_ouput, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "macro_f1 = f1_score(new_ouput, predictions, average='macro')\n",
    "print(\"Macro F1 score:\", macro_f1)\n",
    "\n",
    "auc = roc_auc_score(new_ouput, predictions_probabilities, multi_class='ovr')\n",
    "print(\"AUC score (OvR):\", auc)\n",
    "\n",
    "average_precision = average_precision_score(new_ouput, predictions_probabilities)\n",
    "print(\"Average Precision score:\", average_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4ls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
